{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Module:\n",
    "-  Base class for all neural network\n",
    "-  Your model should be a subclass of this class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "- Define the neural network that has some learnable parameters (or weights)\n",
    "- Iterate over a dataset of inputs\n",
    "- Process input through the network\n",
    "- Compute the loss (how far is the output from being correct)\n",
    "- Propagate gradients back into the networkâ€™s parameters\n",
    "- Update the weights of the network, typically using a simple update rule:<br> weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a model\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1= nn.Conv2d(1,6,5)\n",
    "        self.conv2= nn.Conv2d(6,16,5)\n",
    "        # Fully connected layer\n",
    "        self.fc1= nn.Linear(16*5*5, 120)\n",
    "        self.fc2= nn.Linear(120, 84)\n",
    "        self.fc3= nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max-pooling over a 2*2 window\n",
    "        x= F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x= F.max_pool2d(F.relu(self.conv2(x)), (2))\n",
    "        x= x.view(-1, self.num_flat_features(x))\n",
    "        x= F.relu(self.fc1(x))\n",
    "        x= F.relu(self.fc2(x))\n",
    "        x= self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size= x.size()[1:]\n",
    "        num_features=1\n",
    "        for s in size:\n",
    "            num_features *=s\n",
    "        return num_features\n",
    "    \n",
    "net= Net()\n",
    "print(net)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just have to define forward function and backward function (where gradients are computed) is automatically defined using autograd. You can use any of the tensor operations in the forward function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "<class 'list'>\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# the learnable parameters of model are returned by net.parameters()\n",
    "\n",
    "params= list(net.parameters())\n",
    "print(len(params))\n",
    "print(type(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 0.0043,  0.1449, -0.0757,  0.1509, -0.1416],\n",
      "          [-0.0628, -0.1500, -0.1048,  0.1889,  0.0139],\n",
      "          [-0.1857,  0.1333, -0.1004, -0.0047,  0.0245],\n",
      "          [ 0.0720,  0.0767,  0.1357,  0.1698, -0.0366],\n",
      "          [-0.1198,  0.1219, -0.0371,  0.0031, -0.0397]]],\n",
      "\n",
      "\n",
      "        [[[-0.0076,  0.1303,  0.1844,  0.1236, -0.0340],\n",
      "          [ 0.1379, -0.0718,  0.1191, -0.0846, -0.1061],\n",
      "          [-0.0607,  0.1391, -0.1566,  0.0469,  0.1271],\n",
      "          [ 0.0205,  0.0887, -0.1513,  0.1967, -0.0682],\n",
      "          [ 0.1568,  0.1424,  0.0641, -0.1676, -0.0275]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1285,  0.1013,  0.0299,  0.0101,  0.1316],\n",
      "          [-0.0561, -0.0435,  0.0160, -0.1659, -0.0466],\n",
      "          [-0.1446,  0.0914,  0.1892,  0.0248,  0.1240],\n",
      "          [ 0.1655,  0.0301,  0.1945, -0.0931, -0.0078],\n",
      "          [ 0.0942, -0.1644, -0.0446, -0.0619,  0.1189]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0284,  0.0422, -0.1441,  0.0645,  0.0809],\n",
      "          [ 0.1331, -0.0740, -0.0891, -0.0011,  0.0220],\n",
      "          [ 0.1341, -0.0444, -0.1661, -0.1094,  0.0585],\n",
      "          [ 0.1702, -0.0815,  0.0940,  0.1637, -0.1551],\n",
      "          [-0.0852, -0.1419,  0.0378,  0.0498, -0.1308]]],\n",
      "\n",
      "\n",
      "        [[[-0.1038, -0.1741, -0.1925,  0.0317,  0.1006],\n",
      "          [-0.0532,  0.1751,  0.0185, -0.1672,  0.0569],\n",
      "          [-0.0935, -0.1028, -0.0812,  0.1991,  0.1358],\n",
      "          [ 0.1425, -0.0707, -0.1169,  0.1385,  0.0477],\n",
      "          [ 0.0340,  0.0904,  0.0293, -0.1997, -0.0663]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1503, -0.0477, -0.0914, -0.1241,  0.1155],\n",
      "          [-0.1323,  0.0032,  0.0143,  0.0582,  0.1263],\n",
      "          [ 0.1605,  0.0106,  0.1774,  0.1422, -0.1283],\n",
      "          [-0.0730, -0.1955,  0.1755, -0.0852, -0.1556],\n",
      "          [ 0.0198, -0.1444,  0.0397,  0.1030,  0.1002]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1135,  0.0514,  0.1092, -0.1385,  0.0228, -0.1193], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 5.7790e-02, -9.4909e-03,  4.1850e-02, -8.4006e-03,  1.9536e-02],\n",
      "          [ 1.4945e-02, -1.3240e-02,  5.2444e-03,  2.9596e-02,  4.0106e-02],\n",
      "          [-2.1279e-02, -3.8720e-02,  6.4238e-02, -3.4637e-02,  6.5840e-02],\n",
      "          [-6.6381e-02,  2.1889e-02,  5.4867e-03,  5.8513e-03,  6.8421e-02],\n",
      "          [ 7.8121e-02, -6.5071e-02, -4.8102e-03, -3.3487e-02,  2.4158e-02]],\n",
      "\n",
      "         [[ 6.7393e-02,  6.5592e-02, -7.6796e-02, -5.8957e-02,  4.0735e-02],\n",
      "          [ 3.6588e-02,  6.0492e-02, -4.8300e-02, -8.0525e-02, -5.5511e-02],\n",
      "          [ 7.7058e-02, -7.8027e-02, -3.7372e-02, -4.8889e-03,  3.5562e-02],\n",
      "          [-6.2014e-02,  3.2163e-02, -2.5349e-02,  1.2356e-02,  7.3633e-02],\n",
      "          [-5.0215e-02,  8.0334e-02, -2.5475e-03, -8.1161e-02, -4.2908e-02]],\n",
      "\n",
      "         [[-7.3243e-02, -5.7118e-02, -1.2882e-02, -5.9694e-02, -8.0804e-02],\n",
      "          [ 4.6743e-02,  1.0205e-02,  2.7292e-03, -2.9186e-02,  4.5174e-02],\n",
      "          [-2.1634e-02, -5.8090e-02,  6.8984e-02, -2.8429e-02, -8.0284e-02],\n",
      "          [-4.9002e-02,  3.7657e-02, -6.3174e-02,  1.7952e-02, -5.2103e-02],\n",
      "          [ 7.1018e-02, -7.9226e-02, -8.1632e-02,  5.3530e-03, -3.0481e-02]],\n",
      "\n",
      "         [[-6.2819e-02, -6.1253e-02, -3.4455e-02,  4.1371e-02, -2.4964e-02],\n",
      "          [ 2.0656e-02, -1.5932e-02, -3.9594e-02,  1.1924e-02,  5.3911e-02],\n",
      "          [ 5.1100e-02, -3.6597e-02,  3.9051e-02, -2.1015e-02,  6.0210e-02],\n",
      "          [ 6.0981e-02,  1.0555e-02,  2.6198e-02,  3.8306e-02, -6.4517e-02],\n",
      "          [-2.5845e-02,  2.4955e-02,  3.2149e-02,  6.3154e-02, -4.1107e-02]],\n",
      "\n",
      "         [[ 2.0428e-02,  5.5304e-02,  6.6770e-02, -2.8337e-02,  7.5998e-02],\n",
      "          [-6.4347e-02,  7.6144e-02,  3.4940e-03, -1.7705e-02, -4.3922e-02],\n",
      "          [ 2.2049e-02, -1.4474e-02,  5.9996e-02, -6.1691e-02, -2.3140e-02],\n",
      "          [-4.7736e-02, -6.3684e-02, -4.7683e-02, -5.1677e-02,  3.8849e-03],\n",
      "          [ 6.5213e-02, -1.2569e-02,  1.8740e-02,  3.3896e-02, -3.9484e-02]],\n",
      "\n",
      "         [[ 5.4652e-02, -6.1027e-02, -7.4983e-02,  7.5863e-02, -5.3535e-02],\n",
      "          [ 2.6554e-02, -6.9261e-02,  8.3803e-03,  3.7025e-02,  6.0608e-02],\n",
      "          [ 8.5502e-03, -6.7662e-02,  7.5716e-02, -4.2881e-02, -2.4005e-02],\n",
      "          [ 6.6553e-02, -7.5837e-02,  1.4330e-02, -2.1640e-02, -4.8385e-02],\n",
      "          [ 4.2682e-02,  7.3622e-02,  3.3560e-02,  7.8177e-02, -6.3656e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2655e-02,  3.2979e-02, -5.2560e-02, -1.0199e-02, -2.9195e-02],\n",
      "          [ 7.8202e-02,  1.7802e-02, -2.6361e-02, -4.2908e-02,  3.7956e-03],\n",
      "          [-5.4427e-02, -6.7656e-02, -7.1382e-02, -8.5142e-04,  7.9608e-02],\n",
      "          [ 6.5280e-02, -1.3001e-02, -1.7361e-02,  9.0484e-03,  4.9784e-02],\n",
      "          [ 7.8097e-02,  6.9404e-02, -6.9702e-02,  6.5618e-02, -1.9527e-02]],\n",
      "\n",
      "         [[-4.8418e-03, -3.0675e-02,  2.7327e-02,  2.6020e-02,  4.8345e-02],\n",
      "          [-5.3296e-02, -7.1283e-02, -1.7107e-02, -6.2635e-02,  4.5508e-02],\n",
      "          [ 5.3990e-02, -4.4388e-02, -4.8964e-02, -1.9097e-02, -4.8356e-02],\n",
      "          [-1.4139e-02,  6.2861e-02, -5.6991e-02,  4.5358e-02,  5.0781e-02],\n",
      "          [-7.7708e-02,  4.1396e-02, -4.5617e-02, -7.2582e-03,  5.0213e-02]],\n",
      "\n",
      "         [[-5.3969e-02, -7.4463e-02,  3.1723e-02,  7.1474e-02, -3.9533e-02],\n",
      "          [-9.6722e-03, -2.6484e-02,  7.2983e-02, -1.4471e-03,  2.1497e-02],\n",
      "          [-6.6841e-02, -5.8750e-02, -5.9554e-02,  7.7865e-02, -7.6503e-02],\n",
      "          [-1.1775e-02,  5.9410e-02, -1.3910e-02, -3.5321e-03, -1.8241e-02],\n",
      "          [-1.3611e-02,  6.1094e-02, -7.6399e-02, -3.8958e-02,  6.1203e-02]],\n",
      "\n",
      "         [[ 6.7630e-02, -4.5953e-02,  5.9990e-02,  5.6409e-02, -9.9509e-03],\n",
      "          [ 4.4386e-03,  4.6829e-02,  2.6783e-02, -3.5627e-02, -4.1761e-02],\n",
      "          [-7.6295e-02,  4.9350e-02,  2.5500e-02, -2.0865e-02, -6.5682e-02],\n",
      "          [-6.6286e-02, -2.7857e-02, -7.8097e-02,  5.0847e-02, -7.8096e-02],\n",
      "          [ 3.4973e-02, -3.2912e-02,  3.5359e-02,  2.1085e-06,  1.0606e-02]],\n",
      "\n",
      "         [[-4.7360e-02, -4.0101e-02,  8.0763e-02, -1.7978e-02,  3.4201e-02],\n",
      "          [-2.2157e-02, -2.7805e-02,  4.7865e-02,  4.5615e-02,  6.0632e-02],\n",
      "          [-4.1972e-03,  1.9657e-02,  4.1185e-02,  2.1484e-02,  6.0483e-02],\n",
      "          [ 7.7784e-02,  4.0937e-02,  4.1278e-02,  7.7944e-02,  1.9185e-03],\n",
      "          [-6.0537e-03, -3.3658e-02,  3.0972e-02,  7.6165e-02,  2.7891e-02]],\n",
      "\n",
      "         [[-9.6937e-03,  4.2933e-02,  4.8419e-02,  7.1608e-02, -6.8412e-02],\n",
      "          [-6.2643e-02, -7.8731e-02, -6.0677e-02, -1.3003e-02,  4.8635e-02],\n",
      "          [-7.8565e-02,  2.3281e-02,  6.6457e-02,  7.6290e-02, -6.7685e-02],\n",
      "          [-2.2057e-02,  5.5479e-02, -7.2518e-02,  3.8843e-02,  2.6629e-03],\n",
      "          [ 4.5972e-02, -6.7156e-02, -1.5508e-02,  5.4606e-02,  7.2806e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0745e-02, -5.1052e-03, -7.9752e-02, -5.4650e-02, -2.0254e-02],\n",
      "          [-6.3420e-02,  6.7813e-03,  3.9276e-02,  4.9261e-02,  2.4627e-03],\n",
      "          [-2.7813e-02,  6.0674e-02,  6.8641e-02,  2.1016e-02, -2.2489e-03],\n",
      "          [ 1.1789e-02,  4.9969e-02,  4.7180e-02,  2.9654e-02,  1.8467e-02],\n",
      "          [-3.4064e-02, -5.6998e-02,  7.5759e-02, -3.6816e-02,  4.5916e-02]],\n",
      "\n",
      "         [[ 7.8193e-02, -1.5650e-02, -4.2655e-02, -4.5891e-02, -3.3895e-02],\n",
      "          [-3.9794e-02,  8.0446e-02, -1.3736e-02,  1.7682e-03,  5.0509e-02],\n",
      "          [ 4.5062e-02, -2.3244e-02,  7.5363e-02, -2.0335e-02,  2.3987e-02],\n",
      "          [ 6.9400e-02, -3.3359e-02,  1.6876e-02, -2.3152e-02, -7.0426e-02],\n",
      "          [ 2.6649e-03,  4.1941e-02,  7.4050e-02,  4.1844e-02, -7.7095e-02]],\n",
      "\n",
      "         [[-9.5538e-03, -3.7065e-02,  6.3876e-03,  1.1336e-02,  7.4979e-02],\n",
      "          [ 7.3529e-02,  4.6992e-02,  5.5871e-02, -6.1253e-02,  2.1722e-03],\n",
      "          [ 3.5662e-02, -5.6627e-02, -1.8017e-02,  6.3012e-02, -1.7881e-02],\n",
      "          [ 2.2354e-02,  3.9848e-02, -7.4519e-02, -7.8171e-02, -1.6430e-02],\n",
      "          [ 7.0276e-02,  3.7519e-02, -2.5532e-02,  6.7146e-02, -2.2847e-02]],\n",
      "\n",
      "         [[ 3.9423e-02, -7.4677e-02,  6.4826e-02,  4.3013e-02,  2.1235e-02],\n",
      "          [ 7.1309e-03, -1.3640e-02,  1.3625e-03, -6.0483e-02,  4.0509e-02],\n",
      "          [-7.9050e-02,  7.1929e-02, -2.1090e-02,  7.5233e-02, -4.8395e-02],\n",
      "          [ 1.8169e-02,  1.4766e-02,  2.6710e-02, -7.8477e-02,  8.7901e-03],\n",
      "          [-4.0094e-02, -5.7062e-02, -5.2535e-02, -3.1850e-02,  2.6590e-02]],\n",
      "\n",
      "         [[-4.1528e-02, -3.9209e-02,  2.3889e-02, -6.2100e-02,  7.6577e-02],\n",
      "          [ 6.6291e-02, -4.2394e-02, -5.8361e-02, -3.5235e-02, -7.6009e-02],\n",
      "          [ 6.5441e-03,  6.9947e-02, -2.6284e-02,  2.7762e-02,  4.0093e-02],\n",
      "          [ 1.3447e-02, -6.8058e-02, -5.3944e-02, -1.7320e-02, -4.0664e-02],\n",
      "          [ 7.0506e-02,  2.3991e-02,  1.0012e-02, -5.9831e-02, -5.0926e-02]],\n",
      "\n",
      "         [[-3.0478e-02,  5.4715e-02,  6.6300e-02,  6.9838e-02, -1.8609e-02],\n",
      "          [-2.4391e-02, -3.9938e-02, -4.4573e-02, -6.3087e-02, -7.6108e-02],\n",
      "          [-4.2202e-02,  7.6061e-02, -8.0752e-02,  6.1528e-02,  1.3467e-02],\n",
      "          [-6.7410e-02,  5.8395e-02, -1.4331e-02, -3.1261e-02,  5.8354e-02],\n",
      "          [ 5.9515e-02, -1.6462e-02, -3.0177e-02, -4.6224e-02,  4.6055e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.0175e-02,  4.6249e-02, -1.3926e-02, -5.8070e-02, -2.5103e-02],\n",
      "          [ 2.8087e-02, -6.5213e-02,  2.9159e-02, -5.2013e-02, -3.5581e-02],\n",
      "          [ 2.5374e-02,  4.3998e-02, -2.2250e-02, -7.6271e-02,  7.4362e-02],\n",
      "          [-6.5413e-02,  4.9813e-02,  3.8163e-02,  4.7900e-02, -5.1244e-02],\n",
      "          [-9.6009e-03,  5.5175e-02,  4.3205e-02, -7.9788e-02, -6.4464e-02]],\n",
      "\n",
      "         [[ 1.1897e-02, -7.3532e-02, -2.0404e-02,  6.6585e-02,  2.9913e-02],\n",
      "          [ 4.2233e-02,  3.7220e-02,  4.6279e-02, -4.6269e-02, -6.3472e-02],\n",
      "          [ 5.9828e-02,  6.2204e-02,  6.5191e-03, -6.6429e-03, -6.8380e-02],\n",
      "          [ 2.5669e-03, -4.6577e-02,  5.5486e-02,  5.8106e-03, -7.7894e-02],\n",
      "          [-4.8548e-02,  1.5944e-02, -7.8854e-02, -2.0416e-02, -6.9372e-02]],\n",
      "\n",
      "         [[ 3.7251e-03, -1.4500e-03, -5.8473e-02,  7.9953e-02, -3.0520e-02],\n",
      "          [-6.4885e-02, -2.7495e-02, -7.9828e-03, -3.2043e-02,  7.7299e-02],\n",
      "          [-4.7803e-02, -1.5820e-02, -3.7086e-02, -5.7489e-02,  2.3152e-02],\n",
      "          [ 3.8731e-02, -1.9953e-02,  1.4245e-02,  3.9814e-02, -4.4737e-02],\n",
      "          [ 1.2284e-02, -3.9910e-02,  7.5269e-02, -2.6660e-02, -5.5898e-02]],\n",
      "\n",
      "         [[ 4.9454e-02,  1.6399e-02,  2.8522e-02, -1.8711e-03,  5.6268e-02],\n",
      "          [-3.1938e-02,  8.3962e-03,  7.9292e-02, -7.8031e-02,  4.7245e-02],\n",
      "          [ 1.9109e-04,  3.6013e-02, -2.7104e-02, -3.2740e-02,  6.3790e-02],\n",
      "          [-5.5722e-02,  6.3284e-02, -6.7339e-02,  2.3701e-02,  5.4267e-02],\n",
      "          [-3.8205e-02, -2.9973e-02, -6.3315e-02,  2.6880e-02,  5.5814e-02]],\n",
      "\n",
      "         [[ 4.5466e-02, -1.6180e-02, -6.9643e-02, -4.3352e-02,  7.8397e-03],\n",
      "          [ 3.2186e-02,  2.4239e-02, -2.6334e-02, -3.8893e-02,  9.8419e-03],\n",
      "          [ 3.5443e-02,  7.9458e-02,  2.7712e-02,  5.5896e-02, -4.9930e-02],\n",
      "          [-3.9841e-02,  2.4019e-02, -2.9858e-02,  3.4636e-02,  2.5600e-03],\n",
      "          [ 4.5237e-02, -1.5482e-02, -4.7424e-02, -1.6778e-02, -6.8170e-02]],\n",
      "\n",
      "         [[-1.2526e-02, -3.3301e-02,  6.7779e-02, -6.7217e-02,  2.2768e-02],\n",
      "          [-9.9922e-03,  2.1358e-03, -1.2374e-02, -2.1252e-02, -3.7696e-02],\n",
      "          [ 4.7668e-02,  2.5595e-02,  3.3683e-02,  5.0985e-02,  6.9433e-02],\n",
      "          [-3.2395e-02,  3.4034e-02,  1.7601e-02,  7.4790e-03, -1.7643e-02],\n",
      "          [-2.6546e-02,  1.9859e-03,  5.1376e-02,  5.4828e-02,  6.4175e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4416e-02,  4.9352e-02,  2.1969e-02, -7.0098e-02,  7.2170e-02],\n",
      "          [ 3.5164e-02, -4.0792e-02, -2.7430e-02,  1.6841e-03,  7.8275e-02],\n",
      "          [-7.7534e-02, -3.9819e-03,  4.0220e-02, -3.1628e-04, -2.9305e-03],\n",
      "          [-2.1630e-02, -6.8812e-02,  4.7719e-02,  8.2231e-03,  3.5255e-02],\n",
      "          [ 3.2959e-02, -7.7783e-02, -3.7293e-02, -7.1759e-02, -1.5442e-03]],\n",
      "\n",
      "         [[ 4.9946e-03, -3.0217e-02, -3.4515e-02,  4.1963e-02,  2.7960e-02],\n",
      "          [ 7.7794e-02, -3.2573e-02,  1.2983e-03, -7.0382e-02,  5.9314e-02],\n",
      "          [-4.5795e-02, -8.1252e-02, -6.7553e-02,  1.2952e-02,  4.5749e-02],\n",
      "          [-3.3469e-02, -4.4821e-02,  1.7072e-03, -7.0434e-02,  1.3600e-02],\n",
      "          [ 3.6420e-02,  7.5261e-02,  6.6818e-02, -6.8005e-02,  5.6012e-02]],\n",
      "\n",
      "         [[ 1.6902e-02,  6.7828e-02,  6.0310e-02,  3.2280e-02,  6.3312e-02],\n",
      "          [-3.6642e-03,  6.4460e-02, -3.2928e-02, -6.1858e-02,  3.5605e-02],\n",
      "          [-3.2697e-02, -6.7108e-02, -3.5627e-02, -1.1634e-02, -2.7118e-03],\n",
      "          [ 3.5529e-02, -1.7798e-02,  2.3527e-02,  5.0634e-02, -7.5878e-02],\n",
      "          [-6.6487e-02, -5.5083e-02,  2.0599e-02, -3.5433e-02, -3.2781e-02]],\n",
      "\n",
      "         [[-4.5127e-02, -3.4104e-02,  3.6656e-02,  1.1198e-03, -5.1067e-02],\n",
      "          [ 6.1286e-02, -4.2659e-02,  2.5381e-02,  4.1245e-02,  5.9624e-02],\n",
      "          [-4.5624e-02, -2.5640e-02, -2.9772e-02, -6.0019e-03,  3.3901e-02],\n",
      "          [ 5.8039e-02, -4.3526e-02,  3.1403e-02,  2.8782e-03, -3.5446e-02],\n",
      "          [ 9.7741e-03,  1.5527e-02,  6.9133e-02, -5.0066e-02,  3.3613e-04]],\n",
      "\n",
      "         [[ 4.4198e-02, -2.5284e-02,  7.9399e-02,  3.2502e-02,  3.6042e-02],\n",
      "          [ 1.7075e-02,  2.5648e-02, -3.7556e-03,  1.6090e-02, -4.2800e-02],\n",
      "          [-2.4983e-02,  2.4824e-02, -3.9513e-03, -4.5873e-03, -5.2155e-04],\n",
      "          [ 6.5766e-02,  2.1241e-02,  3.3258e-03, -6.3353e-02, -2.1116e-02],\n",
      "          [ 3.2960e-02, -7.0509e-02, -1.8246e-02,  2.8260e-02,  3.5689e-02]],\n",
      "\n",
      "         [[-7.2329e-02,  1.2283e-02,  1.6860e-03,  1.5697e-02, -4.7320e-02],\n",
      "          [ 2.0112e-02, -1.0950e-02, -3.0585e-02,  7.2064e-02, -2.9776e-02],\n",
      "          [ 2.4543e-02,  1.5821e-03, -1.5696e-02, -3.5793e-03,  1.5883e-02],\n",
      "          [ 2.7785e-02, -1.0837e-02, -3.4034e-02, -7.9751e-02,  4.8559e-02],\n",
      "          [ 3.3793e-02,  2.4264e-02,  8.0810e-02,  7.2539e-02, -4.3068e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3986e-02,  3.4114e-02, -2.5017e-02,  5.7065e-02, -6.5425e-03],\n",
      "          [ 4.7166e-02,  5.9079e-02,  4.6838e-02, -7.3472e-02,  5.8789e-02],\n",
      "          [ 7.3003e-02, -3.6573e-02, -5.3136e-02,  5.4809e-02,  6.6380e-02],\n",
      "          [-2.0054e-02, -6.8153e-02, -4.8964e-02,  4.8386e-02, -3.3799e-02],\n",
      "          [-7.4896e-02, -2.5365e-03,  3.2552e-02,  6.4451e-02,  5.8849e-02]],\n",
      "\n",
      "         [[ 1.2637e-03, -8.0223e-02, -4.2168e-02,  6.9703e-02,  2.9011e-02],\n",
      "          [ 4.7149e-02,  4.5801e-02, -5.6505e-02, -7.5486e-04,  4.2990e-02],\n",
      "          [-5.9137e-02, -7.4844e-02,  7.0280e-02,  6.1769e-02, -7.6526e-02],\n",
      "          [ 6.4586e-02,  1.1987e-02,  7.7017e-02,  4.8415e-02,  5.1920e-02],\n",
      "          [ 6.2617e-02,  6.3149e-02, -7.0503e-02, -4.7068e-02,  5.7094e-02]],\n",
      "\n",
      "         [[-8.0692e-02,  7.4054e-02,  6.0290e-02,  4.4423e-02, -7.8971e-02],\n",
      "          [-1.0357e-04,  3.5632e-02,  5.0960e-02,  6.3731e-02,  1.7555e-02],\n",
      "          [ 4.2481e-03, -6.8491e-02, -4.9313e-02, -2.1227e-02, -1.1245e-02],\n",
      "          [ 2.7647e-03, -4.0800e-02, -2.1006e-02,  7.9483e-04, -6.7543e-02],\n",
      "          [ 6.1647e-02, -7.8326e-02,  2.7158e-02,  2.3779e-02, -2.1574e-02]],\n",
      "\n",
      "         [[-2.7924e-02,  1.8037e-02, -7.3370e-03, -7.9543e-02,  1.9104e-02],\n",
      "          [ 3.5620e-02,  3.7796e-02,  5.8938e-03, -1.2354e-02, -2.5828e-02],\n",
      "          [ 6.1968e-02, -5.7075e-02,  3.7446e-02, -5.5085e-02, -3.9872e-02],\n",
      "          [-6.0746e-02, -7.4198e-02, -2.6950e-02, -1.3488e-02, -6.3176e-02],\n",
      "          [-6.5118e-02, -3.2122e-02,  3.8846e-02,  6.9974e-02, -7.3034e-02]],\n",
      "\n",
      "         [[-3.4659e-03, -1.6576e-03,  7.3962e-02,  5.6386e-02,  3.7142e-02],\n",
      "          [-5.5130e-02,  2.6918e-02,  7.7797e-02, -1.4027e-02, -3.2302e-02],\n",
      "          [ 3.1010e-02, -2.9006e-02, -3.4385e-02, -1.7114e-02, -2.3701e-02],\n",
      "          [-6.3366e-02,  7.3388e-02, -4.2762e-02,  4.7635e-02, -4.7712e-02],\n",
      "          [ 7.6252e-02, -4.4601e-02,  8.9684e-03, -7.8298e-03, -3.6260e-02]],\n",
      "\n",
      "         [[ 3.3647e-02, -4.9268e-02, -3.4264e-02,  3.3796e-02, -1.0420e-02],\n",
      "          [ 7.4394e-02, -6.3844e-02,  1.5185e-02,  3.7019e-02, -4.8444e-02],\n",
      "          [-7.0789e-02,  4.0996e-02,  3.9910e-02, -2.4837e-03, -2.2280e-02],\n",
      "          [ 2.6099e-02, -7.7278e-03, -3.3392e-02, -1.4249e-02, -2.5706e-02],\n",
      "          [-5.2832e-02,  3.6395e-02, -6.9568e-02, -6.6854e-02, -7.3460e-02]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0142,  0.0495, -0.0067,  0.0323,  0.0547, -0.0307, -0.0363,  0.0208,\n",
      "        -0.0602,  0.0069,  0.0269, -0.0649, -0.0359, -0.0746,  0.0168,  0.0296],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0090, -0.0101,  0.0311,  ..., -0.0308, -0.0148,  0.0490],\n",
      "        [ 0.0405, -0.0412,  0.0371,  ...,  0.0215,  0.0434,  0.0332],\n",
      "        [ 0.0458, -0.0397,  0.0013,  ..., -0.0164, -0.0450, -0.0236],\n",
      "        ...,\n",
      "        [-0.0020,  0.0500,  0.0387,  ..., -0.0261,  0.0101,  0.0082],\n",
      "        [-0.0407,  0.0182,  0.0478,  ..., -0.0493,  0.0480, -0.0341],\n",
      "        [ 0.0025,  0.0311, -0.0318,  ..., -0.0446, -0.0279,  0.0220]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0419,  0.0488, -0.0147, -0.0077,  0.0343, -0.0279, -0.0448, -0.0102,\n",
      "         0.0282, -0.0361,  0.0071,  0.0052,  0.0171, -0.0187, -0.0350,  0.0308,\n",
      "        -0.0057,  0.0049, -0.0254,  0.0227,  0.0321, -0.0454,  0.0264, -0.0180,\n",
      "        -0.0393,  0.0195,  0.0010,  0.0146, -0.0317,  0.0230, -0.0494, -0.0173,\n",
      "         0.0003, -0.0192, -0.0354,  0.0003,  0.0168, -0.0225,  0.0417, -0.0053,\n",
      "        -0.0204,  0.0493, -0.0424,  0.0010, -0.0282, -0.0283,  0.0017, -0.0449,\n",
      "         0.0309,  0.0380,  0.0080, -0.0010, -0.0035,  0.0009,  0.0303,  0.0180,\n",
      "        -0.0386,  0.0215, -0.0358, -0.0171, -0.0454,  0.0352,  0.0464, -0.0312,\n",
      "         0.0199,  0.0016,  0.0326, -0.0186,  0.0037,  0.0041, -0.0215,  0.0076,\n",
      "        -0.0130, -0.0189, -0.0009, -0.0171,  0.0360,  0.0294,  0.0086, -0.0160,\n",
      "         0.0238, -0.0380, -0.0025, -0.0120, -0.0230,  0.0186, -0.0029, -0.0173,\n",
      "        -0.0383,  0.0157,  0.0175,  0.0132, -0.0490, -0.0423, -0.0161,  0.0165,\n",
      "        -0.0452, -0.0065,  0.0279,  0.0335,  0.0227, -0.0172,  0.0387, -0.0085,\n",
      "         0.0492,  0.0159, -0.0244,  0.0368, -0.0344,  0.0369,  0.0219,  0.0441,\n",
      "         0.0361,  0.0256, -0.0281,  0.0374,  0.0392, -0.0197,  0.0194,  0.0343],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0221, -0.0765,  0.0121,  ..., -0.0754, -0.0171, -0.0156],\n",
      "        [-0.0309, -0.0665,  0.0110,  ..., -0.0052,  0.0145, -0.0472],\n",
      "        [-0.0222,  0.0566,  0.0257,  ...,  0.0506,  0.0090, -0.0455],\n",
      "        ...,\n",
      "        [ 0.0178,  0.0304, -0.0613,  ..., -0.0421, -0.0152, -0.0761],\n",
      "        [-0.0281, -0.0042, -0.0448,  ...,  0.0800,  0.0043,  0.0661],\n",
      "        [-0.0813, -0.0659, -0.0338,  ...,  0.0518,  0.0093,  0.0476]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0290,  0.0389,  0.0535, -0.0391,  0.0676,  0.0100, -0.0442,  0.0644,\n",
      "        -0.0796, -0.0347, -0.0719,  0.0843, -0.0359,  0.0809,  0.0645,  0.0501,\n",
      "         0.0898, -0.0308,  0.0800, -0.0335, -0.0548,  0.0575,  0.0627, -0.0593,\n",
      "         0.0222, -0.0276, -0.0628, -0.0779, -0.0366, -0.0720,  0.0557,  0.0369,\n",
      "         0.0613, -0.0179, -0.0911, -0.0397, -0.0483, -0.0583,  0.0833, -0.0405,\n",
      "        -0.0761,  0.0240,  0.0287, -0.0299,  0.0701,  0.0384,  0.0831,  0.0793,\n",
      "         0.0455, -0.0681, -0.0661, -0.0781,  0.0104, -0.0620, -0.0479, -0.0873,\n",
      "        -0.0499, -0.0270, -0.0351,  0.0123,  0.0545, -0.0397,  0.0200,  0.0900,\n",
      "        -0.0543,  0.0060, -0.0903, -0.0785,  0.0263, -0.0837,  0.0704,  0.0384,\n",
      "        -0.0479,  0.0365, -0.0271,  0.0176, -0.0357, -0.0641,  0.0040, -0.0009,\n",
      "        -0.0411,  0.0794,  0.0647,  0.0756], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0047, -0.0195, -0.0258, -0.0122, -0.0923,  0.0309,  0.0761,  0.0938,\n",
      "          0.0352,  0.0618,  0.0704,  0.0532, -0.0436,  0.0894, -0.0900,  0.0298,\n",
      "          0.0336,  0.0001, -0.0988, -0.0066,  0.0807, -0.0265,  0.0064,  0.0924,\n",
      "         -0.0149,  0.0341, -0.1033, -0.0171, -0.0980,  0.0654, -0.0362,  0.0059,\n",
      "         -0.0043, -0.0385, -0.0164,  0.0482, -0.0296,  0.0540, -0.0776, -0.0727,\n",
      "         -0.0836,  0.0980,  0.0280,  0.0959, -0.0017, -0.0935,  0.0402, -0.0197,\n",
      "          0.1048,  0.0510,  0.0349, -0.0693,  0.0576,  0.0498, -0.0296, -0.0060,\n",
      "         -0.0876, -0.0327, -0.0316,  0.0284, -0.0425, -0.0951,  0.0502, -0.0071,\n",
      "          0.0992, -0.0619,  0.0264,  0.1090,  0.0996, -0.0558,  0.0554,  0.0536,\n",
      "          0.0744, -0.0463, -0.0736, -0.0929, -0.0968, -0.0661,  0.0441, -0.0487,\n",
      "         -0.0859,  0.0586, -0.0736, -0.0785],\n",
      "        [ 0.0015, -0.0201,  0.1008, -0.0443, -0.0699,  0.0099,  0.0466, -0.0711,\n",
      "         -0.0869, -0.0827,  0.0314,  0.0156, -0.0216,  0.0069, -0.0434, -0.0131,\n",
      "          0.0942, -0.0922, -0.1009, -0.0315, -0.0475, -0.0082, -0.0049,  0.0453,\n",
      "          0.0442,  0.0979, -0.0248,  0.0278, -0.0276,  0.0965, -0.0909, -0.0561,\n",
      "         -0.0334, -0.0276, -0.0188,  0.0101,  0.0308,  0.0513, -0.0520, -0.0071,\n",
      "          0.0683,  0.0266, -0.0938, -0.0725,  0.0407, -0.0470, -0.0727,  0.0846,\n",
      "          0.0350,  0.0242, -0.1091,  0.0983,  0.0072,  0.0400,  0.0822,  0.0859,\n",
      "          0.0619, -0.0941,  0.0466, -0.0311,  0.0653, -0.0125, -0.0119, -0.0722,\n",
      "          0.0556, -0.1022,  0.0209, -0.0067, -0.0133,  0.0993,  0.1016,  0.0510,\n",
      "          0.0537,  0.0883, -0.0768, -0.0618, -0.0123,  0.0735, -0.0713,  0.0575,\n",
      "          0.0401, -0.0531,  0.0601, -0.0612],\n",
      "        [-0.0389, -0.0850,  0.0621,  0.0999, -0.0039,  0.0092, -0.0773, -0.0047,\n",
      "         -0.0052, -0.0304, -0.1090, -0.0015,  0.0256, -0.0896,  0.0535, -0.0061,\n",
      "         -0.0120,  0.0305, -0.0290,  0.0871, -0.0515,  0.0618,  0.0402, -0.0091,\n",
      "          0.0776,  0.0493, -0.1045,  0.0763,  0.0340,  0.0808,  0.0774, -0.0647,\n",
      "         -0.0010, -0.0379,  0.0324, -0.0539, -0.0403, -0.0495, -0.0878,  0.0081,\n",
      "          0.0490,  0.0113, -0.0235, -0.0340, -0.0663, -0.0720, -0.0078, -0.0429,\n",
      "         -0.1043,  0.0397,  0.0258, -0.0054,  0.0638, -0.0851,  0.0634,  0.0155,\n",
      "          0.0298, -0.0835,  0.1016, -0.0304,  0.0894,  0.0120, -0.0608,  0.1081,\n",
      "          0.0607,  0.0225,  0.0854,  0.0431,  0.0027,  0.0987, -0.0489,  0.0123,\n",
      "          0.0893,  0.0222, -0.0299,  0.0490, -0.0938,  0.0990,  0.0544,  0.0468,\n",
      "          0.0259, -0.0759, -0.1025, -0.0330],\n",
      "        [ 0.0306, -0.0383, -0.0240,  0.0981, -0.1082, -0.0490, -0.0250, -0.0686,\n",
      "          0.0066,  0.0828,  0.0698, -0.0243,  0.1067,  0.0531,  0.0177, -0.0554,\n",
      "         -0.0706,  0.0951,  0.0125, -0.0725, -0.0180, -0.0484,  0.0050, -0.0358,\n",
      "         -0.1037,  0.0003, -0.0770,  0.0808, -0.1084, -0.0926, -0.0871, -0.0790,\n",
      "          0.0765,  0.0150,  0.0264, -0.0228, -0.0220, -0.0995,  0.0115,  0.0220,\n",
      "         -0.1054,  0.0856, -0.1025, -0.0675,  0.0625, -0.1066, -0.0694,  0.0228,\n",
      "         -0.0497, -0.0057,  0.1067, -0.0172, -0.1051,  0.0279, -0.0786, -0.0486,\n",
      "          0.0741, -0.0120,  0.0435, -0.0236,  0.0617,  0.0499, -0.0791,  0.0631,\n",
      "         -0.0357, -0.0928,  0.1080, -0.0050,  0.0182, -0.0421, -0.0002,  0.0338,\n",
      "          0.0771, -0.0724, -0.0456, -0.0826,  0.0320, -0.0343,  0.0744, -0.0766,\n",
      "          0.0360, -0.1060, -0.1031, -0.0617],\n",
      "        [ 0.0524, -0.0771, -0.0381, -0.0130,  0.0104, -0.0592, -0.0578,  0.0668,\n",
      "         -0.1012,  0.0186,  0.0054,  0.0324, -0.1025, -0.0029, -0.0567, -0.0160,\n",
      "          0.0330,  0.0394,  0.0717, -0.0934, -0.0078,  0.0822,  0.0369, -0.0543,\n",
      "          0.0198, -0.0986,  0.0306,  0.0174,  0.0707, -0.0428, -0.0932,  0.0050,\n",
      "         -0.0922,  0.0402,  0.1013, -0.0016, -0.0771,  0.0987, -0.0942, -0.0175,\n",
      "         -0.1080,  0.0007,  0.0563, -0.0420,  0.0495, -0.0066,  0.0202, -0.0652,\n",
      "         -0.0052, -0.0567, -0.1028,  0.0948,  0.0838,  0.1055,  0.0121, -0.0639,\n",
      "         -0.0875, -0.0612, -0.0719,  0.0189,  0.1078, -0.0085, -0.0103, -0.0389,\n",
      "         -0.0057,  0.0559,  0.0116, -0.0051, -0.0244,  0.0028, -0.0608,  0.0008,\n",
      "          0.0364,  0.0566,  0.0880,  0.0921, -0.0590,  0.0379,  0.0665,  0.0549,\n",
      "          0.0479,  0.0615,  0.0280, -0.0382],\n",
      "        [ 0.0472,  0.0753,  0.0310,  0.0867, -0.0888, -0.0177,  0.0393,  0.0877,\n",
      "          0.0289, -0.0440,  0.0370, -0.0907, -0.0259, -0.0356, -0.0433, -0.1071,\n",
      "          0.0903, -0.0880, -0.0568,  0.0795, -0.1002,  0.0418, -0.0627,  0.0845,\n",
      "          0.0208,  0.0380, -0.0631,  0.0697,  0.0696,  0.0579, -0.0762,  0.0891,\n",
      "          0.0423,  0.0602,  0.0424,  0.0463,  0.0306, -0.0524, -0.0281, -0.0457,\n",
      "          0.0098, -0.0226, -0.0264, -0.0800, -0.0209,  0.0721, -0.0990,  0.0709,\n",
      "         -0.0153,  0.0796,  0.0500, -0.0230,  0.0892, -0.0959,  0.0927, -0.1072,\n",
      "          0.0793,  0.0455,  0.0977, -0.1060,  0.0374, -0.0096,  0.0470, -0.0625,\n",
      "         -0.0401,  0.0184, -0.0825, -0.0163, -0.0260, -0.0465,  0.1046,  0.0797,\n",
      "          0.0609, -0.0708,  0.0709,  0.0006,  0.0243,  0.0591,  0.0564, -0.0481,\n",
      "         -0.1022,  0.0517,  0.0768, -0.0028],\n",
      "        [-0.0206, -0.1056,  0.0789,  0.0301, -0.0612, -0.0699, -0.0227,  0.0725,\n",
      "          0.0239, -0.0398,  0.0099,  0.0310, -0.0384, -0.0861, -0.0540,  0.0799,\n",
      "          0.0570, -0.0821,  0.0163, -0.0683, -0.0855, -0.0529,  0.0995, -0.0723,\n",
      "          0.0045,  0.0955,  0.0292,  0.0495, -0.0511,  0.0428,  0.1086, -0.0456,\n",
      "          0.0367,  0.0470, -0.0971, -0.0136, -0.0274,  0.0241,  0.0780,  0.1087,\n",
      "          0.0836,  0.0102, -0.0542, -0.1067,  0.1050,  0.0156,  0.0121, -0.0758,\n",
      "         -0.0778, -0.0173,  0.0760, -0.0203, -0.0587,  0.0036,  0.0021,  0.0501,\n",
      "          0.1057,  0.0088, -0.0347,  0.0482,  0.0127,  0.0583, -0.0969,  0.0708,\n",
      "         -0.0990,  0.0785,  0.0496, -0.0263, -0.0131, -0.0105,  0.0356, -0.0240,\n",
      "         -0.0337, -0.0110,  0.0469,  0.0433,  0.0063, -0.0091, -0.0572, -0.0068,\n",
      "          0.0735, -0.0281, -0.0643, -0.1077],\n",
      "        [ 0.0780,  0.0119,  0.0223,  0.0800,  0.0401, -0.0019,  0.0050, -0.0958,\n",
      "         -0.0110, -0.0635,  0.0786, -0.0402, -0.0613, -0.0326,  0.0331,  0.1048,\n",
      "          0.0451,  0.0097, -0.0313,  0.0787,  0.0976,  0.0270, -0.0256, -0.0379,\n",
      "          0.0050,  0.0649,  0.0008,  0.0320, -0.0365, -0.0733,  0.0297,  0.0696,\n",
      "          0.0721,  0.0906, -0.0294,  0.0029, -0.0043, -0.0799, -0.0854,  0.0604,\n",
      "          0.0741, -0.0701,  0.0598,  0.0191, -0.0669,  0.0238, -0.0445, -0.0126,\n",
      "         -0.0088, -0.0519, -0.0041, -0.0804, -0.0393, -0.0501,  0.0347, -0.0308,\n",
      "          0.0333, -0.0733, -0.0468, -0.0757,  0.0560,  0.0519, -0.0273, -0.0829,\n",
      "          0.0132, -0.0038, -0.0008, -0.0433, -0.0130, -0.0767, -0.0317,  0.0475,\n",
      "          0.0709,  0.0194, -0.1060,  0.0345,  0.0846,  0.0661, -0.0077,  0.0101,\n",
      "          0.0427, -0.0310,  0.0498,  0.0424],\n",
      "        [ 0.0854, -0.0823,  0.0461,  0.0025,  0.0953, -0.0837,  0.0644, -0.0352,\n",
      "          0.0862,  0.1083,  0.0939,  0.0418, -0.0788,  0.0149, -0.0569,  0.0022,\n",
      "         -0.0335, -0.0648,  0.0569,  0.0861,  0.0925, -0.0815, -0.0254, -0.0910,\n",
      "          0.0432, -0.1051,  0.1054,  0.0411, -0.0253,  0.0421, -0.0383, -0.0306,\n",
      "          0.0792, -0.0679,  0.1069,  0.0641, -0.0883, -0.0416,  0.0560, -0.0391,\n",
      "         -0.0531, -0.0685,  0.0073,  0.0469, -0.0824,  0.0850, -0.0322, -0.0447,\n",
      "          0.0508, -0.0567,  0.0121,  0.0985, -0.0999,  0.0558,  0.0687, -0.0297,\n",
      "          0.0974, -0.0092, -0.0813, -0.0519,  0.0870, -0.0225,  0.0602,  0.0331,\n",
      "          0.0886, -0.0803,  0.0551,  0.0965,  0.0010, -0.0523, -0.0173, -0.0439,\n",
      "         -0.0151,  0.0440,  0.0517,  0.0055,  0.0314, -0.0833,  0.0498, -0.0975,\n",
      "         -0.0945, -0.0872,  0.0528,  0.0156],\n",
      "        [ 0.1012,  0.0562,  0.1018, -0.0801, -0.0011, -0.0555,  0.0678, -0.0236,\n",
      "          0.0783,  0.0524, -0.0416,  0.0816, -0.0144, -0.0699,  0.0430, -0.0746,\n",
      "         -0.0940,  0.0399, -0.0520, -0.0103, -0.0136, -0.0351,  0.0210, -0.0084,\n",
      "         -0.0076, -0.0583, -0.0786, -0.0233, -0.0561, -0.0227,  0.0491,  0.0951,\n",
      "         -0.0853,  0.0573,  0.0019,  0.0133, -0.0421, -0.0046, -0.0719,  0.0605,\n",
      "          0.0308, -0.0475, -0.0868,  0.0191,  0.0163, -0.0917,  0.0384,  0.0732,\n",
      "         -0.1087, -0.0506,  0.0059,  0.0882, -0.0788, -0.0667, -0.0936,  0.1006,\n",
      "          0.0301, -0.0342, -0.0138,  0.0241,  0.1017, -0.0184, -0.0613,  0.0707,\n",
      "          0.1082,  0.0741, -0.0990, -0.0238,  0.0577, -0.0377, -0.0148,  0.0542,\n",
      "         -0.0488,  0.1055,  0.0713,  0.0660, -0.0741, -0.0635,  0.1063, -0.0288,\n",
      "          0.1080,  0.0630,  0.0283, -0.0730]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0806, -0.0779, -0.1090,  0.0196,  0.0213, -0.0619,  0.0234,  0.0142,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0.0981, -0.0925], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0819,  0.0738, -0.0424,  0.0829,  0.0856,  0.0842,  0.0516, -0.0940,\n",
      "         -0.0035,  0.1297]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function:\n",
    "\n",
    "A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away from output is the target. <br>\n",
    "There are several loss functions under nn package. <br>\n",
    "nn.MSELoss computes the mean squared error between the input and the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "tensor(0.5003, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output= net(input)\n",
    "target= torch.randn(10)  # a dummy target for example\n",
    "target= target.view(1, -1)\n",
    "print(target.size())\n",
    "criterion= nn.MSELoss()\n",
    "\n",
    "loss= criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x000002AB7B5A8A20>\n",
      "<ThAddmmBackward object at 0x000002AB7B5A85F8>\n",
      "<ExpandBackward object at 0x000002AB7B5A8A20>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop:\n",
    "You need to clear the existing gradients though, else gradients will be accumulated to existing gradients.<br>\n",
    "\n",
    "Now we shall call loss.backward(), and have a look at conv1â€™s bias gradients before and after the backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0157,  0.0053,  0.0004, -0.0038, -0.0032,  0.0048])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
